{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29538a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da54725",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764df604",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape = (32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a33523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302c3fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2e642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = layers.Dense(\n",
    "    64,\n",
    "    activation = \"relu\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d497b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dense(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fcf0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15393239",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = layers.Dense(\n",
    "    64,\n",
    "    activation = \"relu\",\n",
    "    )(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09eb09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(\n",
    "    inputs = inputs,\n",
    "    outputs = outputs,\n",
    "    name = \"minist_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614d32cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"minist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,400\n",
      "Trainable params: 54,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06f490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\jimwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\jimwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydot) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9d2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\jimwa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9909d7ad",
   "metadata": {},
   "source": [
    "https://iotespresso.com/how-to-install-graphviz-on-windows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6affbb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    model, \n",
    "    \"my_first_model.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee897c17",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "952cf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "074847b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.attention.multi_head_attention.MultiHeadAttention"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiHeadAttention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
